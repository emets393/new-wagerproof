# âœ… CORRECT ChatKit Metadata Implementation

## The Right Way: ChatKit Client Sends Metadata

The metadata is configured in the **ChatKit config on the frontend**, not sent via BuildShip. ChatKit then sends this metadata with each message to your workflow.

## ğŸ”§ Frontend Configuration (DONE âœ…)

### In ChatKitWrapper.tsx:
```javascript
const chatKitConfig = {
  api: {
    async getClientSecret() {
      // Just get the client secret, no instructions
      return await chatSessionManager.getClientSecret(user);
    }
  },
  // Metadata is configured HERE - ChatKit sends it with each request
  metadata: {
    system_prompt: systemMessage  // All game data included
  },
  theme: { ... },
  composer: { ... }
}
```

## ğŸ“¤ What ChatKit Sends

When you send a message, ChatKit automatically includes the metadata:

```json
{
  "input": {
    "text": "Tell me about the first game"
  },
  "metadata": {
    "system_prompt": "You are WagerBot... [ALL GAME DATA]"
  },
  "workflow": {
    "id": "wf_68ed847d7a44819095f0e8eca93bfd660fc4b093b131f0f0"
  }
}
```

## ğŸ¯ BuildShip Workflow Configuration

### Access Metadata in Your Workflow:
```
{{metadata.system_prompt}}
```

### Use in Model Step:
```yaml
- type: run_model
  model: gpt-4
  input:
    messages:
      - role: system
        content: "{{metadata.system_prompt}}"
      - role: user
        content: "{{input.text}}"
```

## ğŸ“Š Console Output

You'll see:
```
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“¤ CONFIGURING CHATKIT WITH METADATA
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
System prompt will be sent with each message via ChatKit metadata
System prompt length: 8851
System prompt preview: You are WagerBot, an expert sports betting analyst...
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
```

## ğŸ” How to Verify

### 1. Check Console
Look for the purple banner showing metadata configuration

### 2. Check Browser DevTools
- Go to Network tab
- Send a message in chat
- Look for the request to your BuildShip workflow
- Check the payload - should include `metadata.system_prompt`

### 3. Check BuildShip Logs
In your BuildShip workflow execution logs, you should see:
- `metadata` object
- `metadata.system_prompt` with all the game data

### 4. Test the AI
Ask: **"What games do you have data for? List the first 3 with their spreads."**

âœ… **Working:** AI lists specific games with actual data
âŒ **Not Working:** Generic response or "I don't have that data"

## ğŸ¨ Data Flow

```
1. User opens chat
   â†“
2. Frontend configures ChatKit with metadata:
   chatKitConfig = {
     metadata: { system_prompt: "[GAME DATA]" }
   }
   â†“
3. User sends message: "Tell me about Game 1"
   â†“
4. ChatKit sends to BuildShip workflow:
   {
     input: { text: "Tell me about Game 1" },
     metadata: { system_prompt: "[GAME DATA]" }
   }
   â†“
5. BuildShip workflow accesses {{metadata.system_prompt}}
   â†“
6. Passes to OpenAI as system message
   â†“
7. AI responds with context about actual games
```

## âœ… Current Status

**Frontend:** âœ… COMPLETE
- ChatKit configured with metadata
- System prompt includes all game data
- Different metadata per page (NFL vs CFB)
- Clear console logging

**BuildShip:** â³ YOUR TURN
- Access `{{metadata.system_prompt}}` in workflow
- Use it in your model step as system message
- Test and verify

## ğŸ§ª Quick Test

1. Open browser console
2. Go to NFL or College Football page
3. Click chat button
4. Look for purple banner: "ğŸ“¤ CONFIGURING CHATKIT WITH METADATA"
5. Send a message
6. Check BuildShip logs - verify metadata is received
7. Ask AI about specific games

## ğŸ“ BuildShip Workflow Example

```yaml
name: ChatKit with Dynamic Context
trigger: chatkit_message

inputs:
  - input.text (user's message)
  - metadata.system_prompt (game data)

steps:
  - id: log_context
    type: log
    message: "System prompt length: {{metadata.system_prompt.length}}"
  
  - id: call_openai
    type: run_model
    model: gpt-4-turbo
    input:
      messages:
        - role: system
          content: "{{metadata.system_prompt}}"
        - role: user
          content: "{{input.text}}"
  
  - id: return_response
    type: return
    output: "{{call_openai.response}}"
```

## ğŸ‰ Summary

- âœ… ChatKit metadata configured on frontend
- âœ… System prompt with game data included
- âœ… Sent automatically with each message
- âœ… BuildShip can access via `{{metadata.system_prompt}}`
- âœ… No changes needed to session generator
- â³ Just configure your workflow to use the metadata!

The frontend is ready. Now it's all about configuring your BuildShip workflow! ğŸš€

